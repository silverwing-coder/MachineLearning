{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fcf607c-a13e-4f83-9bd1-c42b83e8bfcb",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h4>ver. Jan-2024</h4>\n",
    "\n",
    "<h3>YOLO Predict Model on Video Camera</h3>\n",
    "<h4>Detect person class only</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0460032a-d442-4743-83d1-0fd0b9ce0e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO(\"./models/yolov8n.pt\")\n",
    "\n",
    "# Capture video camera (laptop)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Loop through the video frames\n",
    "while (cap.isOpened()):\n",
    "\n",
    "    # Load a frame from the capture\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if success:\n",
    "        # Run YOLO model and get the pose estimation data from the frame\n",
    "        # Detect person class: classes = 0\n",
    "        # No output on screen: verbose = False\n",
    "        results = model.predict(frame, save=False, imgsz=640, conf=0.5, classes=0, verbose=False)\n",
    " \n",
    "        # Visualize the results on the frame\n",
    "        annotated_frame = results[0].plot()\n",
    "\n",
    "        # Display the annotated frames\n",
    "        cv2.imshow(\"YOLO v8 Pose\", annotated_frame)\n",
    "\n",
    "        if (cv2.waitKey(1) == ord('q')):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Release the resources and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4460f6-d708-4f3b-8d9b-ad88dd3b8778",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br/><h3>YOLO Predict Model on Video Camera</h3>\n",
    "<h4>Segment person class only</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c83fef8d-87e9-4149-b395-efd39e111192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO(\"./models/yolov8n-seg.pt\")\n",
    "\n",
    "# Capture video camera (laptop)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Loop through the video frames\n",
    "while (cap.isOpened()):\n",
    "\n",
    "    # Load a frame from the capture\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if success:\n",
    "        # Run YOLO model and get the pose estimation data from the frame\n",
    "        # Detect person class: classes = 0\n",
    "        # No output on screen: verbose = False\n",
    "        results = model.predict(frame, save=False, imgsz=640, conf=0.5, classes=0, verbose=False)\n",
    " \n",
    "        # Visualize the results on the frame\n",
    "        annotated_frame = results[0].plot()\n",
    "\n",
    "        # Display the annotated frames\n",
    "        cv2.imshow(\"YOLO v8 Pose\", annotated_frame)\n",
    "\n",
    "        if (cv2.waitKey(1) == ord('q')):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Release the resources and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2900aa0-5cd3-498a-87a0-ece46089aabb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
