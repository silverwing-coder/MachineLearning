{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Face Detection on Mediapipe</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install mediapipe library #\n",
    "\n",
    "! pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "from time import time\n",
    "\n",
    "# Create face detector object: must not be in function to prevent repeated object creation\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_face_detector = mp_face_detection.FaceDetection(min_detection_confidence=0.4)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "'''\n",
    "This function performs face(s) detection on an image using mediapipe deep learning based face detector.\n",
    "Args:\n",
    "    image:            The input image with person(s) whose face needs to be detected.\n",
    "    mp_face_detector: The mediapipe's face detection function required to perform the detection.\n",
    "    display:          A boolean value that is if set to true the function displays the original input image,\n",
    "                      and the output image with the bounding boxes, and key points drawn, and also confidence\n",
    "                      scores, and time taken written and returns nothing.\n",
    "Returns:\n",
    "    output_image: A copy of input image with the bounding box and key points drawn and also confidence scores written.\n",
    "    results:      The output of the face detection process on the input image.\n",
    "'''\n",
    "def mpDnnDetectFaces(image, mp_face_detector):\n",
    "\n",
    "\n",
    "    # Get the height and width of the input image.\n",
    "    image_height, image_width, _ = image.shape\n",
    "\n",
    "    # Create a copy of the input image to draw bounding box and key points.\n",
    "    output_image = image.copy()\n",
    "\n",
    "    # Convert the image from BGR into RGB format.\n",
    "    imgRGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Perform the face detection on the image.\n",
    "    results = mp_face_detector.process(imgRGB)\n",
    "\n",
    "    # Check if the face(s) in the image are found.\n",
    "    if results.detections:\n",
    "\n",
    "        # Iterate over the found faces.\n",
    "        for face_no, face in enumerate(results.detections):\n",
    "            # Draw the face bounding box and key points on the copy of the input image.\n",
    "            mp_drawing.draw_detection(image=output_image, detection=face,\n",
    "                                      keypoint_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0),\n",
    "                                                                                   thickness=-1,\n",
    "                                                                                   circle_radius=image_width // 115),\n",
    "                                      bbox_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0),\n",
    "                                                                               thickness=image_width // 180))\n",
    "\n",
    "            # Retrieve the bounding box of the face.\n",
    "            face_bbox = face.location_data.relative_bounding_box\n",
    "\n",
    "            x1 = int(face_bbox.xmin * image_width)\n",
    "            y1 = int(face_bbox.ymin * image_width)\n",
    "\n",
    "            # Draw a filled rectangle near the bounding box of the face.\n",
    "            # We are doing it to change the background of the confidence score to make it easily visible\n",
    "            # cv2.rectangle(output_image, pt1=(x1, y1 - image_width // 20), pt2=(x1 + image_width // 16, y1),\n",
    "            #               color=(0, 255, 0), thickness=3)\n",
    "\n",
    "            # Write the confidence score of the face near the bounding box and on the filled rectangle.\n",
    "            cv2.putText(output_image, text=str(round(face.score[0], 2)), org=(x1, y1 - 25),\n",
    "                        fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=image_width // 600, color=(255, 255, 0),\n",
    "                        thickness=image_width // 200)\n",
    "\n",
    "            # keypoints = face.location_data.relative_keypoints\n",
    "            # print(keypoints)\n",
    "            # 0: left-eye, 1: right-eye, 2: nose, 3: mouse, 4: left-ear, 5: right-ear\n",
    "\n",
    "            keypoint_idx = 0\n",
    "            for keypoint in face.location_data.relative_keypoints:\n",
    "                cv2.putText(output_image, text=str(keypoint_idx), org=(int(keypoint.x*image_width), int(keypoint.y*image_height)),\n",
    "                        fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=1, color=(0, 255, 255),\n",
    "                        thickness=2)\n",
    "                keypoint_idx = keypoint_idx + 1\n",
    "                # print(keypoint_idx, \": [\", int(keypoint.x*image_width), int(keypoint.y*image_height), \"] \")\n",
    "\n",
    "\n",
    "    # Return the output image and results of face detection.\n",
    "    return output_image, results\n",
    "\n",
    "\n",
    "start_time = 0\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "while (capture.isOpened()):\n",
    "\n",
    "    success, frame = capture.read()\n",
    "\n",
    "    # Check if frame is not read properly then continue to the next iteration to read the next frame.\n",
    "    if not success:\n",
    "        continue\n",
    "\n",
    "    # Flip the frame horizontally for natural (selfie-view) visualization.\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Get the height and width of the frame.\n",
    "    frame_height, frame_width, _ = frame.shape\n",
    "\n",
    "    # Perform face detection using the Mediapipe algorithm.\n",
    "    frame, _ = mpDnnDetectFaces(frame, mp_face_detector)\n",
    "\n",
    "    # Write the currently selected method on the frame.\n",
    "    # cv2.putText(frame, (frame_width // 3, frame_height // 8), cv2.FONT_HERSHEY_PLAIN, 4, (255, 155, 0), 3)\n",
    "\n",
    "    # Set the time for this frame to the current time.\n",
    "    end_time = time()\n",
    "\n",
    "    # Check if the difference between the previous and this frame time &gt; 0 to avoid division by zero.\n",
    "    if (end_time - start_time) > 0:\n",
    "        # Calculate the number of frames per second.\n",
    "        frames_per_second = 1.0 / (end_time - start_time)\n",
    "\n",
    "        # Write the calculated number of frames per second on the frame.\n",
    "        cv2.putText(frame, 'FPS: {}'.format(int(frames_per_second)), (10, 30), cv2.FONT_HERSHEY_PLAIN, 2, (0, 255, 0), 3)\n",
    "\n",
    "    # Update the previous frame time to this frame time.\n",
    "    # As this frame will become previous frame in next iteration.\n",
    "    start_time = end_time\n",
    "\n",
    "    cv2.imshow('MediaPipe Face Detection', frame)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
