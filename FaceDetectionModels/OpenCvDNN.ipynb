{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Face Detection on OpenCV DNN</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from time import time\n",
    "\n",
    "# Create face detector object: must not be in function to prevent repeated object creation\n",
    "opencv_dnn_model = cv2.dnn.readNetFromCaffe(prototxt=\"./models/deploy.prototxt\", caffeModel=\"./models/res10_300x300_ssd_iter_140000.caffemodel\")\n",
    "\n",
    "'''\n",
    "This function performs face(s) detection on an image using opencv deep learning based face detector.\n",
    "Args:\n",
    "    image:               The input image of the person(s) whose face needs to be detected.\n",
    "    opencv_dnn_model:    The pre-trained opencv deep learning based face detection model loaded from the disk\n",
    "                         required to perform the detection.\n",
    "    min_confidence:      The minimum detection confidence required to consider the face detection model's\n",
    "                         prediction correct.\n",
    "                         \n",
    "Returns:\n",
    "    output_image: A copy of input image with the bounding boxes drawn and confidence scores written.\n",
    "    results:      The output of the face detection process on the input image.\n",
    "'''\n",
    "def cvDnnDetectFaces(image, opencv_dnn_model, min_confidence=0.5):\n",
    "\n",
    "    # Get the height and width of the input image.\n",
    "    image_height, image_width, _ = image.shape\n",
    "\n",
    "    # Create a copy of the input image to draw bounding boxes and write confidence scores.\n",
    "    output_image = image.copy()\n",
    "\n",
    "    # Perform the required pre-processings on the image and create a 4D blob from image.\n",
    "    # Resize the image and apply mean subtraction to its channels\n",
    "    # Also convert from BGR to RGB format by swapping Blue and Red channels.\n",
    "    preprocessed_image = cv2.dnn.blobFromImage(image, scalefactor=1.0, size=(300, 300),\n",
    "                                               mean=(104.0, 117.0, 123.0), swapRB=False, crop=False)\n",
    "\n",
    "    # Set the input value for the model.\n",
    "    opencv_dnn_model.setInput(preprocessed_image)\n",
    "\n",
    "    # Get the current time before performing face detection.\n",
    "    start = time()\n",
    "\n",
    "    # Perform the face detection on the image.\n",
    "    results = opencv_dnn_model.forward()\n",
    "\n",
    "    # Get the current time after performing face detection.\n",
    "    end = time()\n",
    "\n",
    "    # Loop through each face detected in the image.\n",
    "    for face in results[0][0]:\n",
    "\n",
    "        # Retrieve the face detection confidence score.\n",
    "        face_confidence = face[2]\n",
    "\n",
    "        # Check if the face detection confidence score is greater than the thresold.\n",
    "        if face_confidence > min_confidence:\n",
    "\n",
    "            # Retrieve the bounding box of the face.\n",
    "            bbox = face[3:]\n",
    "\n",
    "            # Retrieve the bounding box coordinates of the face and scale them according to the original size of the image.\n",
    "            x1 = int(bbox[0] * image_width)\n",
    "            y1 = int(bbox[1] * image_height)\n",
    "            x2 = int(bbox[2] * image_width)\n",
    "            y2 = int(bbox[3] * image_height)\n",
    "\n",
    "            # Draw a bounding box around a face on the copy of the image using the retrieved coordinates.\n",
    "            cv2.rectangle(output_image, pt1=(x1, y1), pt2=(x2, y2), color=(0, 255, 0), thickness=image_width // 200)\n",
    "\n",
    "            # Draw a filled rectangle near the bounding box of the face.\n",
    "            # We are doing it to change the background of the confidence score to make it easily visible.\n",
    "            # cv2.rectangle(output_image, pt1=(x1, y1 - image_width // 20), pt2=(x1 + image_width // 16, y1),\n",
    "            #               color=(0, 255, 0), thickness=-1)\n",
    "\n",
    "            # Write the confidence score of the face near the bounding box and on the filled rectangle.\n",
    "            cv2.putText(output_image, text=str(round(face_confidence, 2)), org=(x1, y1 - 25),\n",
    "                        fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=image_width // 600,\n",
    "                        color=(255, 255, 0), thickness=image_width // 200)\n",
    "\n",
    "    # Return the output image and results of face detection.\n",
    "    return output_image, results\n",
    "\n",
    "\n",
    "start_time = 0\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "while (capture.isOpened()):\n",
    "\n",
    "    success, frame = capture.read()\n",
    "\n",
    "    # Check if frame is not read properly then continue to the next iteration to read the next frame.\n",
    "    if not success:\n",
    "        continue\n",
    "\n",
    "    # Flip the frame horizontally for natural (selfie-view) visualization.\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Get the height and width of the frame.\n",
    "    frame_height, frame_width, _ = frame.shape\n",
    "    # Check if the OpenCV DNN algorithm is selected.\n",
    "\n",
    "    # Perform face detection using the OpenCV DNN algorithm.\n",
    "    frame, _ = cvDnnDetectFaces(frame, opencv_dnn_model)\n",
    "\n",
    "    # Write the currently selected method on the frame.\n",
    "    # cv2.putText(frame, (frame_width // 3, frame_height // 8), cv2.FONT_HERSHEY_PLAIN, 4, (255, 155, 0), 3)\n",
    "\n",
    "    # Set the time for this frame to the current time.\n",
    "    end_time = time()\n",
    "\n",
    "    # Check if the difference between the previous and this frame time &gt; 0 to avoid division by zero.\n",
    "    if (end_time - start_time) > 0:\n",
    "        # Calculate the number of frames per second.\n",
    "        frames_per_second = 1.0 / (end_time - start_time)\n",
    "\n",
    "        # Write the calculated number of frames per second on the frame.\n",
    "        cv2.putText(frame, 'FPS: {}'.format(int(frames_per_second)), (10, 30), cv2.FONT_HERSHEY_PLAIN, 2, (0, 255, 0),\n",
    "                    3)\n",
    "\n",
    "    # Update the previous frame time to this frame time.\n",
    "    # As this frame will become previous frame in next iteration.\n",
    "    start_time = end_time\n",
    "\n",
    "    cv2.imshow('OpenCV DNN', frame)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
