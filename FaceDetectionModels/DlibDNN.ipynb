{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Face Detection on Dlib DNN</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dlib library #\n",
    "\n",
    "# ! pip install dlib\n",
    "! pip install dlib-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "from time import time\n",
    "\n",
    "# Create face detector object: must not be in function to prevent repeated object creation\n",
    "cnn_face_detector = dlib.cnn_face_detection_model_v1(\"./models/mmod_human_face_detector.dat\")\n",
    "\n",
    "'''\n",
    "This function performs face(s) detection on an image using dlib deep learning based face detector.\n",
    "Args:\n",
    "    image:              The input image of the person(s) whose face needs to be detected.\n",
    "    cnn_face_detector:  The pre-trained dlib deep learning based (CNN) face detection model loaded from\n",
    "                        the disk required to perform the detection.\n",
    "    new_width:          The new width of the input image to which it will be resized before passing it to the model.\n",
    "    display:            A boolean value that is if set to true the function displays the original input image,\n",
    "                        and the output image with the bounding boxes drawn, confidence scores, and time taken\n",
    "                        written and returns nothing.\n",
    "Returns:\n",
    "    output_image: A copy of input image with the bounding boxes drawn and confidence scores written.\n",
    "    results:      The output of the face detection process on the input image.\n",
    "'''\n",
    "\n",
    "def dlibDnnDetectFaces(image, cnn_face_detector, new_width=600):\n",
    "\n",
    "    # Get the height and width of the input image.\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    # Calculate the new height of the input image while keeping the aspect ratio constant.\n",
    "    new_height = int((new_width / width) * height)\n",
    "\n",
    "    # Resize a copy of input image while keeping the aspect ratio constant.\n",
    "    resized_image = cv2.resize(image.copy(), (new_width, new_height))\n",
    "\n",
    "    # Convert the resized image from BGR into RGB format.\n",
    "    imgRGB = cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Create a copy of the input image to draw bounding boxes and write confidence scores.\n",
    "    output_image = image.copy()\n",
    "\n",
    "    # Get the current time before performing face detection.\n",
    "    start = time()\n",
    "\n",
    "    # Perform the face detection on the image.\n",
    "    results = cnn_face_detector(imgRGB, 0)\n",
    "\n",
    "    # Get the current time after performing face detection.\n",
    "    end = time()\n",
    "\n",
    "    # Loop through each face detected in the image.\n",
    "    for face in results:\n",
    "        # Retriece the bounding box of the face.\n",
    "        bbox = face.rect\n",
    "\n",
    "        # Retrieve the bounding box coordinates and scale them according to the size of original input image.\n",
    "        x1 = int(bbox.left() * (width / new_width))\n",
    "        y1 = int(bbox.top() * (height / new_height))\n",
    "        x2 = int(bbox.right() * (width / new_width))\n",
    "        y2 = int(bbox.bottom() * (height / new_height))\n",
    "\n",
    "        # Draw bounding box around the face on the copy of the image using the retrieved coordinates.\n",
    "        cv2.rectangle(output_image, pt1=(x1, y1), pt2=(x2, y2), color=(0, 255, 0), thickness=width // 200)\n",
    "\n",
    "        # Draw a filled rectangle near the bounding box of the face.\n",
    "        # We are doing it to change the background of the confidence score to make it easily visible.\n",
    "        # cv2.rectangle(output_image, pt1=(x1, y1 - width // 20), pt2=(x1 + width // 16, y1), color=(0, 255, 0),\n",
    "        #               thickness=-1)\n",
    "\n",
    "        # Write the confidence score of the face near the bounding box and on the filled rectangle.\n",
    "        cv2.putText(output_image, text=str(round(face.confidence, 2)), org=(x1, y1 - 25),\n",
    "                    fontFace=cv2.FONT_HERSHEY_COMPLEX,\n",
    "                    fontScale=width // 600, color=(255, 255, 255), thickness=width // 200)\n",
    "\n",
    "    # Return the output image and results of face detection.\n",
    "    return output_image, results\n",
    "\n",
    "\n",
    "\n",
    "start_time = 0\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "while (capture.isOpened()):\n",
    "\n",
    "    success, frame = capture.read()\n",
    "\n",
    "    # Check if frame is not read properly then continue to the next iteration to read the next frame.\n",
    "    if not success:\n",
    "        continue\n",
    "\n",
    "    # Flip the frame horizontally for natural (selfie-view) visualization.\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Get the height and width of the frame.\n",
    "    frame_height, frame_width, _ = frame.shape\n",
    "\n",
    "    # Perform face detection using the Dlib DNN algorithm.\n",
    "    frame, _ = dlibDnnDetectFaces(frame, cnn_face_detector)\n",
    "\n",
    "    # Write the currently selected method on the frame.\n",
    "    # cv2.putText(frame, (frame_width // 3, frame_height // 8), cv2.FONT_HERSHEY_PLAIN, 4, (255, 155, 0), 3)\n",
    "\n",
    "    # Set the time for this frame to the current time.\n",
    "    end_time = time()\n",
    "\n",
    "    # Check if the difference between the previous and this frame time &gt; 0 to avoid division by zero.\n",
    "    if (end_time - start_time) > 0:\n",
    "        # Calculate the number of frames per second.\n",
    "        frames_per_second = 1.0 / (end_time - start_time)\n",
    "\n",
    "        # Write the calculated number of frames per second on the frame.\n",
    "        cv2.putText(frame, 'FPS: {}'.format(int(frames_per_second)), (10, 30), cv2.FONT_HERSHEY_PLAIN, 2, (0, 255, 0),\n",
    "                    3)\n",
    "\n",
    "    # Update the previous frame time to this frame time.\n",
    "    # As this frame will become previous frame in next iteration.\n",
    "    start_time = end_time\n",
    "\n",
    "    cv2.imshow('Haar Cascade', frame)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
